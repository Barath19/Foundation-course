{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d455e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e375622",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a218eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data using sklearn function\n",
    "bunch = fetch_california_housing(download_if_missing=True, as_frame=True)\n",
    "\n",
    "# Load the dataframe and view\n",
    "df = bunch.frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76361df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bunch.frame\n",
    "x = df.iloc[:,:-1] # Select all the columns, except the last column\n",
    "y = df.iloc[:,-1:] # Select the last column\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 1)\n",
    "\n",
    "input_scalar = StandardScaler()\n",
    "output_scalar = StandardScaler()\n",
    "\n",
    "x_train = input_scalar.fit_transform(x_train).T # Normalize train data\n",
    "x_test = input_scalar.transform(x_test).T # Only transform test data using values of train data\n",
    "\n",
    "y_train = output_scalar.fit_transform(y_train).reshape(-1)\n",
    "y_test = output_scalar.transform(y_test).reshape(-1)\n",
    "\n",
    "dataset_copy = [ x_train.copy(), x_test.copy(),  y_train.copy(),  y_test.copy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ba078",
   "metadata": {},
   "source": [
    "# Linear Regression Model -Supervised Learning\n",
    "\n",
    "Now we define our linear regression model from scratch.\n",
    "\n",
    "A linear regression model is of the form:\n",
    "\n",
    "$y = a_1 x_1 + a_2 x_2 + \\dots + a_nx_n + a_{n+1}$\n",
    "  \n",
    "The above can be rewritten using matrix multiplication as\n",
    "\n",
    "$ y = w^T x $\n",
    "\n",
    "where \n",
    "\n",
    "$ w = [a_1, a_2, \\dots,  a_n, a_{n+1}]^T $\n",
    "\n",
    "$ x = [x_1, x_2, \\dots,  x_n]^T $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36683b88",
   "metadata": {},
   "source": [
    "![lr](https://user-images.githubusercontent.com/81376570/122819892-02032a80-d2a9-11eb-993b-a3069f9df662.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self, dim, lr = 0.1):\n",
    "        assert isinstance\n",
    "        self.lr = lr\n",
    "        self.w = np.zeros((dim))\n",
    "        self.grads = {\"dw\": np.zeros((dim)) +5}\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.w.T @ x\n",
    "        return y\n",
    "  \n",
    "    def backward(self, x, y_hat, y):\n",
    "        assert y_hat.shape == y.shape\n",
    "        self.grads[\"dw\"] = (1 / x.shape[1]) * ((y_hat - y) @ x.T).T\n",
    "        assert self.grads[\"dw\"].shape == self.w.shape\n",
    "    \n",
    "    # print(self.grads[\"dw\"])\n",
    "    def optimize(self):\n",
    "        self.w = self.w - self.lr * self.grads[\"dw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9864ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "w_history = []\n",
    "dim = x_train.shape[0]\n",
    "num_train = x_train.shape[1]\n",
    "num_test = x_test.shape[1]\n",
    "\n",
    "\n",
    "model = LinearRegression(dim = dim, lr = 0.1)\n",
    "for i in range(num_epochs):\n",
    "    y_hat = model.forward(x_train)\n",
    "    train_loss = 1/(2 * num_train) * ((y_train - y_hat) ** 2).sum()\n",
    "    w_history.append(model.w)\n",
    "    model.backward(x_train,y_hat,y_train)\n",
    "    model.optimize()\n",
    "\n",
    "    y_hat = model.forward(x_test)\n",
    "    test_loss = 1/(2 * num_test) * ((y_test - y_hat) ** 2).sum()\n",
    "\n",
    "    train_loss_history.append(train_loss)\n",
    "    test_loss_history.append(test_loss)\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Epoch {i} | Train Loss {train_loss} | Test Loss {test_loss}\")\n",
    "\n",
    "#plt.plot(range(num_epochs), train_loss_history, label = \"Training\")\n",
    "#plt.plot(range(num_epochs), test_loss_history, label = \"Test\")\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314b629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x_train, x_test, y_train, y_test = dataset_copy\n",
    "lr = LR()\n",
    "lr.fit(x_train.T, y_train)\n",
    "y_hat = lr.predict(x_test.T)\n",
    "y_test = output_scalar.inverse_transform(y_test[np.newaxis,:])\n",
    "y_hat  = output_scalar.inverse_transform(y_hat[np.newaxis,:])\n",
    "error = mean_squared_error(y_test, y_hat, squared = True)\n",
    "print(\"Test Set Error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5eb7e",
   "metadata": {},
   "source": [
    "## Clustering -Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19199926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import Birch\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
    "# define the model\n",
    "model = Birch(threshold=0.01, n_clusters=2)\n",
    "# fit the model\n",
    "model.fit(X)\n",
    "# assign a cluster to each example\n",
    "yhat = model.predict(X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in clusters:\n",
    "    # get row indexes for samples with this cluster\n",
    "    row_ix = where(yhat == cluster)\n",
    "    # create scatter of these samples\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f00edf",
   "metadata": {},
   "source": [
    "## Reinforcement learning\n",
    "\n",
    "![RL](https://pytorch.org/tutorials/_images/mario.gif)\n",
    "![rl](http://ai.stanford.edu/blog/assets/img/posts/2019-09-05-acteach/task-path-place.gif)\n",
    "![rl](https://www.pair.toronto.edu/assets/img/teaser/graspd-eccv22.gif)\n",
    "![rl](https://huggingface.co/blog/assets/78_deep_rl_dqn/atari-envs.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c266b90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install gym-notebook-wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15fc4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import gym\n",
    "import math\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from gym import wrappers\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "tdir = tempfile.mkdtemp()\n",
    "\n",
    "env = gym.make('FrozenLake-v1')\n",
    "np.random.seed(56776)\n",
    "q_learning_table = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "\n",
    "# -- hyper --\n",
    "num_epis = 500\n",
    "num_iter = 200\n",
    "learning_rate = 0.2\n",
    "discount = 0.9\n",
    "\n",
    "# -- training the agent ----\n",
    "for epis in range(num_epis):\n",
    "    \n",
    "    state = env.reset()\n",
    "\n",
    "    for iter in range(num_iter):\n",
    "        action = np.argmax(q_learning_table[state,:] + np.random.randn(1,4))\n",
    "        state_new,reward,done,_ = env.step(action)\n",
    "        q_learning_table[state,action] = (1-learning_rate)* q_learning_table[state,action] + \\\n",
    "                                         learning_rate * (reward + discount*np.max(q_learning_table[state_new,:]) )\n",
    "        state = state_new\n",
    "\n",
    "        if done: break\n",
    "\n",
    "print(np.argmax(q_learning_table,axis=1))\n",
    "print(np.around(q_learning_table,5))\n",
    "print('-------------------------------')\n",
    "s = env.reset()\n",
    "for _ in range(500):\n",
    "    action  = np.argmax(q_learning_table[s,:])\n",
    "    state_new,_,done,_ = env.step(action)\n",
    "    env.render()\n",
    "    s = state_new\n",
    "    if done: break\n",
    "    \n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e45fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f15c1a9",
   "metadata": {},
   "source": [
    "## YOLO - Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403fe63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Will take sometime to download torch 730mb\n",
    "#!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "%cd yolov5\n",
    "%pip install -r requirements.txt  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23739099",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 detect.py --source 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec1227",
   "metadata": {},
   "source": [
    "## Facial Landmark Detection - DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66bc622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1141e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        # Draw the face mesh annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_tesselation_style())\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_contours_style())\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_iris_connections_style())\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Face Mesh', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07f741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa18cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
